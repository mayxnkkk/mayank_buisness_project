{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack Overflow 2018 Developer Survey Analysis\n",
    "## Salary Prediction & Skill Clustering in the Global Software Market\n",
    "\n",
    "# **Dataset:** Stack Overflow 2018 Developer Survey  \n",
    "# **Objective:** Examine salary trends and skill demand using regression-based salary prediction and K-Means clustering  \n",
    "# **Tools:** pandas, numpy, matplotlib, seaborn, scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a5d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f24ac",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Data Loading & Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 2. LOAD DATA (Fetched from Kaggle)\n",
    "# ========================\n",
    "import os\n",
    "import shutil\n",
    "import kagglehub\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "public_csv = os.path.join(DATA_DIR, 'survey_results_public.csv')\n",
    "schema_csv = os.path.join(DATA_DIR, 'survey_results_schema.csv')\n",
    "\n",
    "# Download from Kaggle if not already present\n",
    "if not os.path.exists(public_csv):\n",
    "    print(\"â¬‡ï¸  Downloading Stack Overflow 2018 Developer Survey from Kaggle...\")\n",
    "    path = kagglehub.dataset_download(\"stackoverflow/stack-overflow-2018-developer-survey\")\n",
    "    print(f\"   Downloaded to: {path}\")\n",
    "    # Copy CSVs into our data/ folder\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.csv'):\n",
    "            shutil.copy2(os.path.join(path, f), DATA_DIR)\n",
    "    print(f\"   Copied CSVs to: {DATA_DIR}\")\n",
    "else:\n",
    "    print(\"âœ… Dataset already exists in data/ â€” skipping download\")\n",
    "\n",
    "df = pd.read_csv(public_csv)\n",
    "schema = pd.read_csv(schema_csv)\n",
    "\n",
    "print(f\"\\nâœ… Data loaded from: {DATA_DIR}\")\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Total Respondents: {df.shape[0]:,}\")\n",
    "print(f\"Total Features: {df.shape[1]}\")\n",
    "print(\"\\n--- First 5 Rows ---\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a3dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info about the dataset\n",
    "print(\"--- Data Types & Non-Null Counts ---\")\n",
    "print(df.info())\n",
    "print(\"\\n--- Statistical Summary ---\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e150c8",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Data Cleaning & Preprocessing\n",
    "\n",
    "### Cleaning Strategy & Rationale\n",
    "\n",
    "| Data Issue | Strategy | Why |\n",
    "|---|---|---|\n",
    "| **Missing salary (`ConvertedSalary`)** | **Delete** rows with null/zero salary | Salary is our prediction target â€” imputing it (mean/median) would fabricate the very value we're trying to predict, introducing circular bias into both regression and clustering. |\n",
    "| **Salary outliers** | **Delete** rows outside 1stâ€“99th percentile | Extreme values (e.g., $1 or $10M/year) are likely data-entry errors. They skew the mean, distort regression coefficients, and pull K-Means centroids. |\n",
    "| **Missing categorical features** (Country, DevType, Gender, etc.) | **Fill with `'Unknown'`** (a new category) | Deleting every row with any missing categorical would slash the dataset (many columns have 10-30% missing). `'Unknown'` preserves the row's other valid data. For multi-value fields like `LanguageWorkedWith`, `'Unknown'` maps to 0 skills â€” neutral and interpretable. |\n",
    "| **Missing ordinal features** (YearsCoding, Satisfaction, Education) | **Fill with neutral midpoint** (0 for years, 4 for satisfaction, 3 for education) | These are mapped to manual numeric scales. A neutral midpoint avoids pulling averages in either direction. This is more semantically meaningful than a blind statistical median for categorical/ordinal data. |\n",
    "\n",
    "> **Why no median imputation?** For the target variable, deletion is the only honest choice. For features, category-aware filling (`'Unknown'` / neutral value) is more interpretable than a blind statistical median â€” especially since most features here are categorical or ordinal, not continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3a. SELECT RELEVANT COLUMNS & MISSING VALUE ANALYSIS\n",
    "# ========================\n",
    "\n",
    "# Select relevant columns for analysis\n",
    "cols_of_interest = [\n",
    "    'Country', 'Employment', 'FormalEducation', 'UndergradMajor',\n",
    "    'CompanySize', 'DevType', 'YearsCoding', 'YearsCodingProf',\n",
    "    'JobSatisfaction', 'CareerSatisfaction', 'ConvertedSalary',\n",
    "    'LanguageWorkedWith', 'FrameworkWorkedWith', 'DatabaseWorkedWith',\n",
    "    'PlatformWorkedWith', 'Gender', 'Age', 'Exercise', 'HoursComputer'\n",
    "]\n",
    "\n",
    "df_clean = df[cols_of_interest].copy()\n",
    "print(f\"Selected {len(cols_of_interest)} columns for analysis\")\n",
    "\n",
    "# --- Missing Value Analysis ---\n",
    "missing = df_clean.isnull().sum()\n",
    "missing_pct = (missing / len(df_clean) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing %', ascending=False)\n",
    "print(\"\\n--- Missing Values (Top Columns) ---\")\n",
    "print(missing_df)\n",
    "\n",
    "# Visualize missing data\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "missing_df['Missing %'].plot(kind='barh', color='coral', edgecolor='black', ax=ax)\n",
    "ax.set_title('Missing Data Percentage by Feature', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Missing %')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1adbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3b. DROP MISSING SALARY & FILTER OUTLIERS\n",
    "# ========================\n",
    "\n",
    "# STRATEGY: DELETE rows where salary is missing or zero.\n",
    "# WHY: ConvertedSalary is our prediction TARGET â€” imputing it with mean/median\n",
    "# would fabricate the value we're trying to predict, creating circular bias\n",
    "# in both the regression model and K-Means clustering.\n",
    "df_clean = df_clean.dropna(subset=['ConvertedSalary'])\n",
    "df_clean = df_clean[df_clean['ConvertedSalary'] > 0]\n",
    "\n",
    "print(f\"Rows after dropping missing/zero salary: {len(df_clean):,}\")\n",
    "\n",
    "# STRATEGY: DELETE extreme salary outliers (keep within 1st and 99th percentile).\n",
    "# WHY: Values like $1/year or $10M/year are likely data-entry errors.\n",
    "# They skew the mean, distort regression coefficients, and pull K-Means\n",
    "# cluster centroids away from meaningful positions.\n",
    "q1 = df_clean['ConvertedSalary'].quantile(0.01)\n",
    "q99 = df_clean['ConvertedSalary'].quantile(0.99)\n",
    "df_clean = df_clean[(df_clean['ConvertedSalary'] >= q1) & (df_clean['ConvertedSalary'] <= q99)]\n",
    "print(f\"Rows after removing salary outliers (1st-99th percentile): {len(df_clean):,}\")\n",
    "print(f\"Salary range: ${df_clean['ConvertedSalary'].min():,.0f} - ${df_clean['ConvertedSalary'].max():,.0f}\")\n",
    "print(f\"Mean Salary: ${df_clean['ConvertedSalary'].mean():,.0f}\")\n",
    "print(f\"Median Salary: ${df_clean['ConvertedSalary'].median():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3c. ENCODE CATEGORICAL VARIABLES & FILL MISSING VALUES\n",
    "# ========================\n",
    "\n",
    "# STRATEGY: FILL missing categorical values with 'Unknown' (a new category).\n",
    "# WHY: Deleting every row with any missing categorical value would slash the\n",
    "# dataset dramatically (many columns have 10-30% missing). 'Unknown' preserves\n",
    "# the row's other valid data. For multi-value fields like LanguageWorkedWith,\n",
    "# 'Unknown' naturally maps to 0 skills â€” a neutral, interpretable value.\n",
    "cat_cols = df_clean.select_dtypes(include='object').columns.tolist()\n",
    "for col in cat_cols:\n",
    "    df_clean[col] = df_clean[col].fillna('Unknown')\n",
    "\n",
    "# STRATEGY: Map ordinal features to numeric values, FILL missing with NEUTRAL MIDPOINTS.\n",
    "# WHY: These are manual numeric scales (not continuous), so a neutral midpoint\n",
    "# avoids pulling averages in either direction. This is more semantically\n",
    "# meaningful than a blind statistical median for categorical/ordinal data.\n",
    "\n",
    "# Map YearsCoding / YearsCodingProf to numeric midpoints (Unknown â†’ 0 years)\n",
    "years_map = {\n",
    "    '0-2 years': 1, '3-5 years': 4, '6-8 years': 7,\n",
    "    '9-11 years': 10, '12-14 years': 13, '15-17 years': 16,\n",
    "    '18-20 years': 19, '21-23 years': 22, '24-26 years': 25,\n",
    "    '27-29 years': 28, '30 or more years': 32, 'Unknown': 0\n",
    "}\n",
    "df_clean['YearsCoding_Num'] = df_clean['YearsCoding'].map(years_map).fillna(0)\n",
    "df_clean['YearsCodingProf_Num'] = df_clean['YearsCodingProf'].map(years_map).fillna(0)\n",
    "\n",
    "# Map JobSatisfaction to numeric (Unknown â†’ 4, the neutral middle of 1-7 scale)\n",
    "satisfaction_map = {\n",
    "    'Extremely dissatisfied': 1, 'Moderately dissatisfied': 2,\n",
    "    'Slightly dissatisfied': 3, 'Neither satisfied nor dissatisfied': 4,\n",
    "    'Slightly satisfied': 5, 'Moderately satisfied': 6,\n",
    "    'Extremely satisfied': 7, 'Unknown': 4\n",
    "}\n",
    "df_clean['JobSatisfaction_Num'] = df_clean['JobSatisfaction'].map(satisfaction_map).fillna(4)\n",
    "df_clean['CareerSatisfaction_Num'] = df_clean['CareerSatisfaction'].map(satisfaction_map).fillna(4)\n",
    "\n",
    "# Count number of languages, frameworks, databases, platforms known\n",
    "# ('Unknown' â†’ 0 skills, which is the natural neutral value)\n",
    "df_clean['Num_Languages'] = df_clean['LanguageWorkedWith'].apply(\n",
    "    lambda x: len(str(x).split(';')) if x != 'Unknown' else 0\n",
    ")\n",
    "df_clean['Num_Frameworks'] = df_clean['FrameworkWorkedWith'].apply(\n",
    "    lambda x: len(str(x).split(';')) if x != 'Unknown' else 0\n",
    ")\n",
    "df_clean['Num_Databases'] = df_clean['DatabaseWorkedWith'].apply(\n",
    "    lambda x: len(str(x).split(';')) if x != 'Unknown' else 0\n",
    ")\n",
    "df_clean['Num_Platforms'] = df_clean['PlatformWorkedWith'].apply(\n",
    "    lambda x: len(str(x).split(';')) if x != 'Unknown' else 0\n",
    ")\n",
    "df_clean['Total_Skills'] = (df_clean['Num_Languages'] + df_clean['Num_Frameworks'] +\n",
    "                             df_clean['Num_Databases'] + df_clean['Num_Platforms'])\n",
    "\n",
    "# Label encode Education (Unknown â†’ 3, mid-range neutral value)\n",
    "edu_order = {\n",
    "    'I never completed any formal education': 0,\n",
    "    'Primary/elementary school': 1,\n",
    "    'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)': 2,\n",
    "    'Some college/university study without earning a degree': 3,\n",
    "    'Associate degree': 4,\n",
    "    \"Bachelor's degree (BA, BS, B.Eng., etc.)\": 5,\n",
    "    \"Master's degree (MA, MS, M.Eng., MBA, etc.)\": 6,\n",
    "    'Professional degree (JD, MD, etc.)': 7,\n",
    "    'Other doctoral degree (Ph.D, Ed.D., etc.)': 8,\n",
    "    'Unknown': 3\n",
    "}\n",
    "df_clean['Education_Level'] = df_clean['FormalEducation'].map(edu_order).fillna(3)\n",
    "\n",
    "print(f\"âœ… Feature engineering complete!\")\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n",
    "print(f\"\\nNew numeric features created:\")\n",
    "print(\"  - YearsCoding_Num, YearsCodingProf_Num\")\n",
    "print(\"  - JobSatisfaction_Num, CareerSatisfaction_Num\")\n",
    "print(\"  - Num_Languages, Num_Frameworks, Num_Databases, Num_Platforms\")\n",
    "print(\"  - Total_Skills, Education_Level\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85739c3",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Exploratory Data Analysis (EDA)\n",
    "Visualizing salary distributions, top countries, skill demand, and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc659e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4a. SALARY DISTRIBUTION\n",
    "# ========================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df_clean['ConvertedSalary'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribution of Annual Salary (USD)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Converted Salary (USD)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(df_clean['ConvertedSalary'].median(), color='red', linestyle='--', label=f\"Median: ${df_clean['ConvertedSalary'].median():,.0f}\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df_clean['ConvertedSalary'], vert=True, patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue'))\n",
    "axes[1].set_title('Salary Box Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Converted Salary (USD)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fbc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4b. TOP 15 COUNTRIES BY MEDIAN SALARY\n",
    "# ========================\n",
    "country_salary = (df_clean.groupby('Country')['ConvertedSalary']\n",
    "                  .agg(['median', 'count'])\n",
    "                  .rename(columns={'median': 'Median_Salary', 'count': 'Respondents'})\n",
    "                  .query('Respondents >= 50')\n",
    "                  .sort_values('Median_Salary', ascending=False)\n",
    "                  .head(15))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "bars = ax.barh(country_salary.index[::-1], country_salary['Median_Salary'][::-1],\n",
    "               color=plt.cm.viridis(np.linspace(0.3, 0.9, 15)), edgecolor='black')\n",
    "ax.set_title('Top 15 Countries by Median Developer Salary', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Median Annual Salary (USD)')\n",
    "for i, (val, count) in enumerate(zip(country_salary['Median_Salary'][::-1], country_salary['Respondents'][::-1])):\n",
    "    ax.text(val + 1000, i, f'${val:,.0f} (n={count})', va='center', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Insight: The US, Switzerland, and Israel typically lead in developer compensation,\")\n",
    "print(\"   reflecting high demand-supply gaps in their tech labor markets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4c. TOP PROGRAMMING LANGUAGES BY POPULARITY\n",
    "# ========================\n",
    "# Explode the semicolon-separated languages\n",
    "all_languages = df_clean['LanguageWorkedWith'].str.split(';').explode()\n",
    "lang_counts = all_languages.value_counts().head(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, 20))\n",
    "lang_counts[::-1].plot(kind='barh', color=colors, edgecolor='black', ax=ax)\n",
    "ax.set_title('Top 20 Programming Languages (by Developer Usage)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Number of Developers')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Insight: JavaScript, HTML/CSS, SQL dominate - reflecting web-centric demand.\")\n",
    "print(\"   Python's strong position highlights the growing data science & AI market.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4d. SALARY BY EDUCATION LEVEL\n",
    "# ========================\n",
    "edu_salary = (df_clean.groupby('FormalEducation')['ConvertedSalary']\n",
    "              .median()\n",
    "              .sort_values(ascending=True))\n",
    "# Keep only meaningful education levels\n",
    "edu_salary = edu_salary[edu_salary.index != 'Unknown']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "edu_salary.plot(kind='barh', color='teal', edgecolor='black', ax=ax)\n",
    "ax.set_title('Median Salary by Education Level', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Median Annual Salary (USD)')\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Insight: Higher education correlates with higher salaries, but the gap between\")\n",
    "print(\"   Bachelor's and Master's is relatively small â€” signaling experience matters more.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78891457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4e. SALARY vs EXPERIENCE (Scatter + Trend)\n",
    "# ========================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Salary vs Years Coding\n",
    "axes[0].scatter(df_clean['YearsCoding_Num'], df_clean['ConvertedSalary'],\n",
    "                alpha=0.1, s=10, color='steelblue')\n",
    "# Add trend line\n",
    "z = np.polyfit(df_clean['YearsCoding_Num'], df_clean['ConvertedSalary'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(0, 35, 100)\n",
    "axes[0].plot(x_line, p(x_line), 'r-', linewidth=2, label=f'Trend (slope={z[0]:,.0f})')\n",
    "axes[0].set_title('Salary vs Years of Coding Experience', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Years Coding')\n",
    "axes[0].set_ylabel('Annual Salary (USD)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Salary vs Total Skills\n",
    "axes[1].scatter(df_clean['Total_Skills'], df_clean['ConvertedSalary'],\n",
    "                alpha=0.1, s=10, color='darkorange')\n",
    "z2 = np.polyfit(df_clean['Total_Skills'], df_clean['ConvertedSalary'], 1)\n",
    "p2 = np.poly1d(z2)\n",
    "x_line2 = np.linspace(0, df_clean['Total_Skills'].max(), 100)\n",
    "axes[1].plot(x_line2, p2(x_line2), 'r-', linewidth=2, label=f'Trend (slope={z2[0]:,.0f})')\n",
    "axes[1].set_title('Salary vs Total Technical Skills', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Total Skills (Languages + Frameworks + DBs + Platforms)')\n",
    "axes[1].set_ylabel('Annual Salary (USD)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Insight: Both experience and breadth of skills show positive correlation with salary.\")\n",
    "print(\"   This supports the human capital theory â€” investment in skills yields returns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4f. CORRELATION HEATMAP\n",
    "# ========================\n",
    "numeric_cols = ['ConvertedSalary', 'YearsCoding_Num', 'YearsCodingProf_Num',\n",
    "                'JobSatisfaction_Num', 'CareerSatisfaction_Num', 'Education_Level',\n",
    "                'Num_Languages', 'Num_Frameworks', 'Num_Databases', 'Num_Platforms',\n",
    "                'Total_Skills']\n",
    "\n",
    "corr_matrix = df_clean[numeric_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, square=True, linewidths=0.5, ax=ax,\n",
    "            cbar_kws={'label': 'Correlation Coefficient'})\n",
    "ax.set_title('Correlation Heatmap of Numeric Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Insight: Experience (YearsCodingProf) shows the strongest correlation with salary.\")\n",
    "print(\"   Individual skill counts are moderately correlated with each other (multi-skilled devs).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387cfea",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. K-Means Clustering â€” Developer Skill Segmentation\n",
    "Clustering developers based on their skill profiles to identify distinct market segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 5a. PREPARE FEATURES FOR CLUSTERING\n",
    "# ========================\n",
    "cluster_features = ['YearsCoding_Num', 'YearsCodingProf_Num', 'Education_Level',\n",
    "                    'Num_Languages', 'Num_Frameworks', 'Num_Databases',\n",
    "                    'Num_Platforms', 'Total_Skills', 'ConvertedSalary']\n",
    "\n",
    "df_cluster = df_clean[cluster_features].dropna()\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_cluster)\n",
    "\n",
    "print(f\"Clustering dataset shape: {df_cluster.shape}\")\n",
    "print(f\"Features used: {cluster_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313958d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 5b. ELBOW METHOD â€” FIND OPTIMAL K\n",
    "# ========================\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, labels, sample_size=5000, random_state=42))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Elbow curve\n",
    "axes[0].plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_title('Elbow Method â€” Optimal K', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Clusters (K)')\n",
    "axes[0].set_ylabel('Inertia (Within-Cluster Sum of Squares)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Silhouette scores\n",
    "axes[1].plot(K_range, silhouette_scores, 'rs-', linewidth=2, markersize=8)\n",
    "axes[1].set_title('Silhouette Score vs K', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Number of Clusters (K)')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nâœ… Best K by Silhouette Score: {best_k}\")\n",
    "print(f\"   Silhouette Scores: {dict(zip(K_range, [round(s, 4) for s in silhouette_scores]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb0c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 5c. FIT K-MEANS WITH OPTIMAL K (using K=4 as a balanced choice)\n",
    "# ========================\n",
    "optimal_k = 4  # Using 4 clusters for clear business segmentation\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10, max_iter=300)\n",
    "df_cluster['Cluster'] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "# Cluster summary statistics\n",
    "cluster_summary = df_cluster.groupby('Cluster').agg({\n",
    "    'ConvertedSalary': ['mean', 'median', 'count'],\n",
    "    'YearsCoding_Num': 'mean',\n",
    "    'YearsCodingProf_Num': 'mean',\n",
    "    'Total_Skills': 'mean',\n",
    "    'Education_Level': 'mean',\n",
    "    'Num_Languages': 'mean'\n",
    "}).round(1)\n",
    "\n",
    "cluster_summary.columns = ['Avg Salary', 'Median Salary', 'Count',\n",
    "                            'Avg YearsCoding', 'Avg YearsProf',\n",
    "                            'Avg TotalSkills', 'Avg Education', 'Avg Languages']\n",
    "\n",
    "# Assign meaningful labels based on characteristics\n",
    "print(\"=\" * 80)\n",
    "print(\"K-MEANS CLUSTER PROFILES\")\n",
    "print(\"=\" * 80)\n",
    "print(cluster_summary.to_string())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Rename clusters based on salary and experience\n",
    "cluster_labels = cluster_summary.sort_values('Median Salary')\n",
    "for i, (idx, row) in enumerate(cluster_labels.iterrows()):\n",
    "    labels = ['ğŸŸ¢ Entry-Level / Junior', 'ğŸ”µ Mid-Level / Generalist',\n",
    "              'ğŸŸ¡ Senior / Specialist', 'ğŸ”´ Expert / High-Earner']\n",
    "    print(f\"Cluster {idx}: {labels[i]}\")\n",
    "    print(f\"  Median Salary: ${row['Median Salary']:,.0f} | Avg Experience: {row['Avg YearsProf']:.1f} yrs | Avg Skills: {row['Avg TotalSkills']:.1f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 5d. VISUALIZE CLUSTERS\n",
    "# ========================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "colors = ['#2ecc71', '#3498db', '#f1c40f', '#e74c3c']\n",
    "\n",
    "# Plot 1: Salary vs Experience by Cluster\n",
    "for c in range(optimal_k):\n",
    "    mask = df_cluster['Cluster'] == c\n",
    "    axes[0].scatter(df_cluster.loc[mask, 'YearsCodingProf_Num'],\n",
    "                    df_cluster.loc[mask, 'ConvertedSalary'],\n",
    "                    alpha=0.3, s=15, color=colors[c], label=f'Cluster {c}')\n",
    "axes[0].set_title('Clusters: Salary vs Professional Experience', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Years Coding Professionally')\n",
    "axes[0].set_ylabel('Annual Salary (USD)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Salary vs Total Skills by Cluster\n",
    "for c in range(optimal_k):\n",
    "    mask = df_cluster['Cluster'] == c\n",
    "    axes[1].scatter(df_cluster.loc[mask, 'Total_Skills'],\n",
    "                    df_cluster.loc[mask, 'ConvertedSalary'],\n",
    "                    alpha=0.3, s=15, color=colors[c], label=f'Cluster {c}')\n",
    "axes[1].set_title('Clusters: Salary vs Total Skills', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Total Technical Skills')\n",
    "axes[1].set_ylabel('Annual Salary (USD)')\n",
    "axes[1].legend()\n",
    "\n",
    "# Plot 3: Cluster size distribution\n",
    "cluster_counts = df_cluster['Cluster'].value_counts().sort_index()\n",
    "axes[2].bar(cluster_counts.index, cluster_counts.values, color=colors, edgecolor='black')\n",
    "axes[2].set_title('Cluster Size Distribution', fontsize=13, fontweight='bold')\n",
    "axes[2].set_xlabel('Cluster')\n",
    "axes[2].set_ylabel('Number of Developers')\n",
    "for i, v in enumerate(cluster_counts.values):\n",
    "    axes[2].text(i, v + 100, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Business Insight: The clusters reveal distinct labor market segments â€”\")\n",
    "print(\"   from entry-level generalists to highly-specialized senior developers.\")\n",
    "print(\"   Companies can use these segments for targeted recruitment & compensation benchmarking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1992a9",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Linear Regression â€” Salary Prediction Model\n",
    "Building a regression model to predict developer salary based on experience, skills, and education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 6a. PREPARE FEATURES FOR REGRESSION\n",
    "# ========================\n",
    "feature_cols = ['YearsCoding_Num', 'YearsCodingProf_Num', 'Education_Level',\n",
    "                'Num_Languages', 'Num_Frameworks', 'Num_Databases',\n",
    "                'Num_Platforms', 'Total_Skills', 'JobSatisfaction_Num',\n",
    "                'CareerSatisfaction_Num']\n",
    "\n",
    "target = 'ConvertedSalary'\n",
    "\n",
    "# Drop NaN\n",
    "df_reg = df_clean[feature_cols + [target]].dropna()\n",
    "\n",
    "X = df_reg[feature_cols]\n",
    "y = df_reg[target]\n",
    "\n",
    "# Train-Test Split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"Test set:     {X_test.shape[0]:,} samples\")\n",
    "print(f\"Features:     {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409269d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 6b. TRAIN LINEAR REGRESSION MODEL\n",
    "# ========================\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = lr_model.predict(X_train)\n",
    "y_pred_test = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LINEAR REGRESSION MODEL PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Metric':<25} {'Train':>15} {'Test':>15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'RÂ² Score':<25} {train_r2:>15.4f} {test_r2:>15.4f}\")\n",
    "print(f\"{'RMSE (USD)':<25} {train_rmse:>15,.0f} {test_rmse:>15,.0f}\")\n",
    "print(f\"{'Mean Salary (USD)':<25} {y_train.mean():>15,.0f} {y_test.mean():>15,.0f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 6c. FEATURE IMPORTANCE (Regression Coefficients)\n",
    "# ========================\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': lr_model.coef_\n",
    "}).sort_values('Coefficient', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = ['#e74c3c' if c < 0 else '#2ecc71' for c in coef_df['Coefficient']]\n",
    "ax.barh(coef_df['Feature'], coef_df['Coefficient'], color=colors, edgecolor='black')\n",
    "ax.set_title('Linear Regression â€” Feature Coefficients (Impact on Salary)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Coefficient Value (USD impact per unit increase)')\n",
    "ax.axvline(x=0, color='black', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Interpretation:\")\n",
    "for _, row in coef_df.iterrows():\n",
    "    direction = \"increases\" if row['Coefficient'] > 0 else \"decreases\"\n",
    "    print(f\"  â€¢ 1 unit increase in {row['Feature']} {direction} salary by ~${abs(row['Coefficient']):,.0f}\")\n",
    "print(f\"\\n  Intercept (base salary): ${lr_model.intercept_:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 6d. ACTUAL vs PREDICTED â€” VISUALIZATION\n",
    "# ========================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter: Actual vs Predicted\n",
    "axes[0].scatter(y_test, y_pred_test, alpha=0.2, s=10, color='steelblue')\n",
    "max_val = max(y_test.max(), y_pred_test.max())\n",
    "axes[0].plot([0, max_val], [0, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_title('Actual vs Predicted Salary', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Actual Salary (USD)')\n",
    "axes[0].set_ylabel('Predicted Salary (USD)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Residual distribution\n",
    "residuals = y_test - y_pred_test\n",
    "axes[1].hist(residuals, bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='black', linewidth=1.5, linestyle='--')\n",
    "axes[1].set_title('Residual Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Residual (Actual - Predicted) USD')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean Residual: ${residuals.mean():,.0f}\")\n",
    "print(f\"Std of Residuals: ${residuals.std():,.0f}\")\n",
    "print(\"\\nğŸ“Š Insight: The residuals are approximately normally distributed around 0,\")\n",
    "print(\"   indicating no systematic bias in predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c03f1",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Business Interpretation & Economic Analysis\n",
    "Linking data science findings to real-world economic and financial concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12793253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 7a. SALARY BY DEVELOPER TYPE â€” DEMAND-SUPPLY ANALYSIS\n",
    "# ========================\n",
    "# Explode DevType (semicolon-separated)\n",
    "df_dev = df_clean[['DevType', 'ConvertedSalary']].copy()\n",
    "df_dev = df_dev[df_dev['DevType'] != 'Unknown']\n",
    "df_dev_exploded = df_dev.assign(DevType=df_dev['DevType'].str.split(';')).explode('DevType')\n",
    "\n",
    "dev_stats = (df_dev_exploded.groupby('DevType')['ConvertedSalary']\n",
    "             .agg(['median', 'count'])\n",
    "             .rename(columns={'median': 'Median_Salary', 'count': 'Supply'})\n",
    "             .query('Supply >= 100')\n",
    "             .sort_values('Median_Salary', ascending=False))\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Plot median salary\n",
    "color1 = 'steelblue'\n",
    "bars = ax1.barh(dev_stats.index[::-1], dev_stats['Median_Salary'][::-1],\n",
    "                color=color1, alpha=0.7, edgecolor='black', label='Median Salary')\n",
    "ax1.set_xlabel('Median Salary (USD)', color=color1)\n",
    "ax1.set_title('Developer Roles: Salary vs Supply (Demand-Supply Dynamics)', fontsize=14, fontweight='bold')\n",
    "ax1.tick_params(axis='x', labelcolor=color1)\n",
    "\n",
    "# Overlay supply count\n",
    "ax2 = ax1.twiny()\n",
    "color2 = 'coral'\n",
    "ax2.plot(dev_stats['Supply'][::-1], dev_stats.index[::-1], 'D-', color=color2,\n",
    "         markersize=5, linewidth=1.5, label='Developer Supply')\n",
    "ax2.set_xlabel('Number of Developers (Supply)', color=color2)\n",
    "ax2.tick_params(axis='x', labelcolor=color2)\n",
    "\n",
    "fig.legend(loc='lower right', bbox_to_anchor=(0.95, 0.05))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Economic Insight â€” Demand-Supply Analysis:\")\n",
    "print(\"   â€¢ Roles like Engineering Manager and DevOps command HIGH salary with LOWER supply\")\n",
    "print(\"     â†’ Classic supply shortage driving up equilibrium wages\")\n",
    "print(\"   â€¢ Full-stack/Web developers have HIGH supply but MODERATE salary\")\n",
    "print(\"     â†’ Competitive market with more supply meeting demand\")\n",
    "print(\"   â€¢ Data Scientists show RISING salary â€” reflecting growing demand outpacing supply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 7b. SKILL PREMIUM ANALYSIS â€” ROI ON LEARNING LANGUAGES\n",
    "# ========================\n",
    "# For each language, compute median salary of devs who know it vs those who don't\n",
    "all_langs = df_clean['LanguageWorkedWith'].str.split(';').explode().value_counts()\n",
    "top_langs = all_langs.head(15).index.tolist()\n",
    "\n",
    "lang_premiums = []\n",
    "for lang in top_langs:\n",
    "    knows = df_clean[df_clean['LanguageWorkedWith'].str.contains(lang, na=False)]['ConvertedSalary'].median()\n",
    "    doesnt = df_clean[~df_clean['LanguageWorkedWith'].str.contains(lang, na=False)]['ConvertedSalary'].median()\n",
    "    premium = knows - doesnt\n",
    "    lang_premiums.append({'Language': lang, 'Median_With': knows, 'Median_Without': doesnt, 'Premium': premium})\n",
    "\n",
    "premium_df = pd.DataFrame(lang_premiums).sort_values('Premium', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "colors = ['#e74c3c' if p < 0 else '#27ae60' for p in premium_df['Premium']]\n",
    "ax.barh(premium_df['Language'], premium_df['Premium'], color=colors, edgecolor='black')\n",
    "ax.set_title('Salary Premium by Programming Language (Knowing vs Not Knowing)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Salary Premium (USD)')\n",
    "ax.axvline(x=0, color='black', linewidth=0.8)\n",
    "for i, (_, row) in enumerate(premium_df.iterrows()):\n",
    "    ax.text(row['Premium'] + (500 if row['Premium'] >= 0 else -500), i,\n",
    "            f\"${row['Premium']:+,.0f}\", va='center', fontsize=9,\n",
    "            ha='left' if row['Premium'] >= 0 else 'right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Revenue Optimization Insight:\")\n",
    "print(\"   â€¢ Languages like Go, Scala, and Objective-C carry a SALARY PREMIUM\")\n",
    "print(\"     â†’ Specialized/niche skills in high-demand create pricing power\")\n",
    "print(\"   â€¢ Common languages (PHP, CSS) show lower premiums\")\n",
    "print(\"     â†’ Commodity skills face downward wage pressure due to oversupply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 7c. FINAL SUMMARY â€” MODEL COMPARISON TABLE\n",
    "# ========================\n",
    "final_sil = silhouette_score(X_scaled, kmeans_final.labels_, sample_size=5000, random_state=42)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL MODEL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ MODEL 1: K-Means Clustering (Skill Segmentation)                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Number of Clusters:     {optimal_k}                                            â”‚\n",
    "â”‚ Silhouette Score:       {final_sil:.4f}                                      â”‚\n",
    "â”‚ Features Used:          {len(cluster_features)}                                            â”‚\n",
    "â”‚ Business Use:           Developer market segmentation, hiring strategy â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ MODEL 2: Linear Regression (Salary Prediction)                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ RÂ² Score (Train):       {train_r2:.4f}                                      â”‚\n",
    "â”‚ RÂ² Score (Test):        {test_r2:.4f}                                      â”‚\n",
    "â”‚ RMSE (Test):            ${test_rmse:,.0f}                                   â”‚\n",
    "â”‚ Features Used:          {len(feature_cols)}                                           â”‚\n",
    "â”‚ Business Use:           Salary benchmarking, compensation planning     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Key Economic & Business Takeaways:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "1. DEMAND-SUPPLY: Specialized roles (DevOps, ML Engineers) command salary\n",
    "   premiums due to supply shortages in the labor market.\n",
    "\n",
    "2. HUMAN CAPITAL THEORY: Professional experience is the strongest predictor\n",
    "   of salary â€” each additional year adds significant earning potential.\n",
    "\n",
    "3. PRICING STRATEGY: Companies can use cluster profiles to set competitive\n",
    "   salary bands for different developer tiers.\n",
    "\n",
    "4. RISK ANALYSIS: Over-reliance on common skills (JS, HTML) carries wage\n",
    "   stagnation risk; diversifying into niche technologies hedges this.\n",
    "\n",
    "5. REVENUE OPTIMIZATION: Hiring from lower-cost clusters while upskilling\n",
    "   them can optimize engineering budget allocation.\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
